{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "#lines = lines.pop(0)\n",
    "for line in lines[1:]:\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = './data/IMG/' + filename\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'speed'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0][-1]\n",
    "#source_path\n",
    "#current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/7\n",
      "6428/6428 [==============================] - 8s - loss: 4875480.5198 - val_loss: 4428.1938\n",
      "Epoch 2/7\n",
      "6428/6428 [==============================] - 8s - loss: 3660.6958 - val_loss: 2625.8169\n",
      "Epoch 3/7\n",
      "6428/6428 [==============================] - 8s - loss: 2554.7666 - val_loss: 2227.6700\n",
      "Epoch 4/7\n",
      "6428/6428 [==============================] - 8s - loss: 2123.7398 - val_loss: 1769.2834\n",
      "Epoch 5/7\n",
      "6428/6428 [==============================] - 8s - loss: 2385.1122 - val_loss: 3042.1658\n",
      "Epoch 6/7\n",
      "6428/6428 [==============================] - 8s - loss: 2536.4234 - val_loss: 1878.7871\n",
      "Epoch 7/7\n",
      "6428/6428 [==============================] - 8s - loss: 4045.2438 - val_loss: 6724.5042\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(160,320,3)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=7)\n",
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Second try: lambda layers\n",
    "In Keras, lambda layers can be used to create arbitrary functions that operate on each image as it passes through the layer.\n",
    "\n",
    "In this project, a lambda layer is a convenient way to parallelize image normalization. The lambda layer will also ensure that the model will normalize input images when making predictions in drive.py.\n",
    "\n",
    "That lambda layer could take each pixel in an image and run it through the formulas:\n",
    "\n",
    "pixel_normalized = pixel / 255\n",
    "\n",
    "pixel_mean_centered = pixel_normalized - 0.5\n",
    "\n",
    "A lambda layer will look something like:\n",
    "\n",
    "Lambda(lambda x: (x / 255.0) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/2\n",
      "6428/6428 [==============================] - 8s - loss: 2.2740 - val_loss: 1.8223\n",
      "Epoch 2/2\n",
      "6428/6428 [==============================] - 8s - loss: 3.7297 - val_loss: 3.5815\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x/255.0)-0.5, input_shape=(160,320,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=2)\n",
    "model.save('model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use epoch=7, makes the model loss go up and down. So it could be overfitting, so reduce to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/5\n",
      "6428/6428 [==============================] - 26s - loss: 1.7542 - val_loss: 0.0170\n",
      "Epoch 2/5\n",
      "6428/6428 [==============================] - 24s - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 3/5\n",
      "6428/6428 [==============================] - 24s - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 4/5\n",
      "6428/6428 [==============================] - 24s - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 5/5\n",
      "6428/6428 [==============================] - 24s - loss: 0.0106 - val_loss: 0.0124\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x/255.0)-0.5, input_shape=(160,320,3)))\n",
    "model.add(Convolution2D(6,5,5,activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6,5,5,activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=5)\n",
    "model.save('model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "Problem is the car like to steering to the left, since it's a loop.\n",
    "\n",
    "Flipping Images And Steering Measurements\n",
    "A effective technique for helping with the left turn bias involves flipping images and taking the opposite sign of the steering measurement. For example:\n",
    "\n",
    "import numpy as np\n",
    "image_flipped = np.fliplr(image)\n",
    "measurement_flipped = -measurement\n",
    "The cv2 library also has similar functionality with the flip method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmented_images, augmented_measurements = [], []\n",
    "for image, measurement in zip(images, measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image,1))\n",
    "    augmented_measurements.append(measurement*-1.0)\n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/5\n",
      "6428/6428 [==============================] - 25s - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 2/5\n",
      "6428/6428 [==============================] - 25s - loss: 0.0079 - val_loss: 0.0126\n",
      "Epoch 3/5\n",
      "6428/6428 [==============================] - 25s - loss: 0.0059 - val_loss: 0.0133\n",
      "Epoch 4/5\n",
      "6428/6428 [==============================] - 25s - loss: 0.0048 - val_loss: 0.0138\n",
      "Epoch 5/5\n",
      "6428/6428 [==============================] - 25s - loss: 0.0035 - val_loss: 0.0154\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=5)\n",
    "model.save('model4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Multiple Cameras\n",
    "The simulator captures images from three cameras mounted on the car: a center, right and left camera. That’s because of the issue of recovering from being off-center.\n",
    "\n",
    "In the simulator, you can weave all over the road and turn recording on and off to record recovery driving. In a real car, however, that’s not really possible. At least not legally.\n",
    "\n",
    "So in a real car, we’ll have multiple cameras on the vehicle, and we’ll map recovery paths from each camera. For example, if you train the model to associate a given image from the center camera with a left turn, then you could also train the model to associate the corresponding image from the left camera with a somewhat softer left turn. And you could train the model to associate the corresponding image from the right camera with an even harder left turn.\n",
    "\n",
    "In that way, you can simulate your vehicle being in different positions, somewhat further off the center line. To read more about this approach, see [this paper](http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf) by our friends at NVIDIA that makes use of this technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of How Multiple Cameras Work\n",
    "The image below gives a sense for how multiple cameras are used to train a self-driving car. This image shows a bird's-eye perspective of the car. The driver is moving forward but wants to turn towards a destination on the left.\n",
    "\n",
    "From the perspective of the left camera, the steering angle would be less than the steering angle from the center camera. From the right camera's perspective, the steering angle would be larger than the angle from the center camera. The next section will discuss how this can be implemented in your project although there is no requirement to use the left and right camera images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!()[https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/46a70500-493e-4057-a78e-b3075933709d/concepts/2cd424ad-a661-4754-8421-aec8cb018005#]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Cameras in This Project\n",
    "For this project, recording recoveries from the sides of the road back to center is effective. But it is also possible to use all three camera images to train the model. When recording, the simulator will simultaneously save an image for the left, center and right cameras. Each row of the csv log file, driving_log.csv, contains the file path for each camera as well as information about the steering measurement, throttle, brake and speed of the vehicle.\n",
    "Here is some example code to give an idea of how all three images can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "images = []\n",
    "measurements = []        \n",
    "for row in lines[1:]:\n",
    "    steering_center = float(row[3])\n",
    "    # create adjusted steering measurements for the side camera images\n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    steering_right = steering_center - correction\n",
    "\n",
    "    # read in images from center, left and right cameras\n",
    "    path = \"./data/IMG/\" # fill in the path to your training IMG directory\n",
    "    img_center = cv2.imread(path + row[0].split('/')[-1])\n",
    "    img_left   = cv2.imread(path + row[1].split('/')[-1])\n",
    "    img_right  = cv2.imread(path + row[2].split('/')[-1])\n",
    "\n",
    "    # add images and angles to data set\n",
    "    images.append(img_center)\n",
    "    images.append(img_left)\n",
    "    images.append(img_right)\n",
    "    measurements.append(steering_center)\n",
    "    measurements.append(steering_left)\n",
    "    measurements.append(steering_right)\n",
    "\n",
    "    \n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "During training, you want to feed the left and right camera images to your model as if they were coming from the center camera. This way, you can teach your model how to steer if the car drifts off to the left or the right.\n",
    "\n",
    "Figuring out how much to add or subtract from the center angle will involve some experimentation.\n",
    "\n",
    "During prediction (i.e. \"autonomous mode\"), you only need to predict with the center camera image.\n",
    "\n",
    "It is not necessary to use the left and right images to derive a successful model. Recording recovery driving from the sides of the road is also effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/5\n",
      "19286/19286 [==============================] - 80s - loss: 0.5049 - val_loss: 0.0155\n",
      "Epoch 2/5\n",
      "19286/19286 [==============================] - 76s - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 3/5\n",
      "19286/19286 [==============================] - 76s - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 4/5\n",
      "19286/19286 [==============================] - 76s - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 5/5\n",
      "19286/19286 [==============================] - 76s - loss: 0.0076 - val_loss: 0.0123\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x/255.0)-0.5, input_shape=(160,320,3)))\n",
    "model.add(Convolution2D(6,5,5,activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6,5,5,activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=5)\n",
    "model.save('model5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping Images in Keras\n",
    "The cameras in the simulator capture 160 pixel by 320 pixel images.\n",
    "\n",
    "Not all of these pixels contain useful information, however. In the image above, the top portion of the image captures trees and hills and sky, and the bottom portion of the image captures the hood of the car.\n",
    "\n",
    "Your model might train faster if you crop each image to focus on only the portion of the image that is useful for predicting a steering angle.\n",
    "Cropping2D Layer\n",
    "Keras provides the Cropping2D layer for image cropping within the model. This is relatively fast, because the model is parallelized on the GPU, so many images are cropped simultaneously.\n",
    "\n",
    "By contrast, image cropping outside the model on the CPU is relatively slow.\n",
    "\n",
    "Also, by adding the cropping layer, the model will automatically crop the input images when making predictions in drive.py.\n",
    "\n",
    "The Cropping2D layer might be useful for choosing an area of interest that excludes the sky and/or the hood of the car.\n",
    "\n",
    "Here is an example of an input image and its cropped version after passing through a Cropping2D layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x/255.0)-0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "model.add(Convolution2D(6,5,5,activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6,5,5,activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/5\n",
      "19286/19286 [==============================] - 42s - loss: 0.0295 - val_loss: 0.0211\n",
      "Epoch 2/5\n",
      "19286/19286 [==============================] - 42s - loss: 0.0161 - val_loss: 0.0247\n",
      "Epoch 3/5\n",
      "19286/19286 [==============================] - 42s - loss: 0.0144 - val_loss: 0.0204\n",
      "Epoch 4/5\n",
      "19286/19286 [==============================] - 42s - loss: 0.0136 - val_loss: 0.0187\n",
      "Epoch 5/5\n",
      "19286/19286 [==============================] - 42s - loss: 0.0130 - val_loss: 0.0214\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=5)\n",
    "model.save('model6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NVIDIA Architecture\n",
    "\n",
    "https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x/255.0)-0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(54,3,3,activation=\"relu\"))\n",
    "model.add(Convolution2D(54,3,3,activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0115 - val_loss: 0.0180\n",
      "Epoch 2/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0105 - val_loss: 0.0207\n",
      "Epoch 3/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0096 - val_loss: 0.0176\n",
      "Epoch 4/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0086 - val_loss: 0.0183\n",
      "Epoch 5/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0080 - val_loss: 0.0201\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=5)\n",
    "model.save('model7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Data Collection\n",
    "Recovery Laps\n",
    "If you drive and record normal laps around the track, even if you record a lot of them, it might not be enough to train your model to drive properly.\n",
    "\n",
    "Here’s the problem: if your training data is all focused on driving down the middle of the road, your model won’t ever learn what to do if it gets off to the side of the road. And probably when you run your model to predict steering measurements, things won’t go perfectly and the car will wander off to the side of the road at some point.\n",
    "\n",
    "So you need to teach the car what to do when it’s off on the side of the road.\n",
    "\n",
    "One approach might be to constantly wander off to the side of the road and then steer back to the middle.\n",
    "\n",
    "A better approach is to only record data when the car is driving from the side of the road back toward the center line.\n",
    "\n",
    "So as the human driver, you’re still weaving back and forth between the middle of the road and the shoulder, but you need to turn off data recording when you weave out to the side, and turn it back on when you steer back to the middle.\n",
    "\n",
    "### Driving Counter-Clockwise\n",
    "Track one has a left turn bias. If you only drive around the first track in a clock-wise direction, the data will be biased towards left turns. One way to combat the bias is to turn the car around and record counter-clockwise laps around the track. Driving counter-clockwise is also like giving the model a new track to learn from, so the model will generalize better.\n",
    "### Using Both Tracks\n",
    "If you end up using data from only track one, the convolutional neural network could essentially memorize the track. Consider using data from both track one and track two to make a more generalized model.\n",
    "### Collecting Enough Data\n",
    "How do you know when you have collected enough data? Machine learning involves trying out ideas and testing them to see if they work. If the model is over or underfitting, then try to figure out why and adjust accordingly.\n",
    "\n",
    "Since this model outputs a single continuous numeric value, one appropriate error metric would be mean squared error. If the mean squared error is high on both a training and validation set, the model is underfitting. If the mean squared error is low on a training set but high on a validation set, the model is overfitting. Collecting more data can help improve a model when the model is overfitting.\n",
    "\n",
    "What if the model has a low mean squared error on both the training and validation sets, but the car is falling off the track?\n",
    "\n",
    "Try to figure out the cases where the vehicle is falling off the track. Does it occur only on turns? Then maybe it's important to collect more turning data. The vehicle's driving behavior is only as good as the behavior of the driver who provided the data.\n",
    "\n",
    "Here are some general guidelines for data collection:\n",
    "\n",
    "two or three laps of center lane driving\n",
    "one lap of recovery driving from the sides\n",
    "one lap focusing on driving smoothly around curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Loss\n",
    "Outputting Training and Validation Loss Metrics\n",
    "In Keras, the model.fit() and model.fit_generator() methods have a verbose parameter that tells Keras to output loss metrics as the model trains. The verbose parameter can optionally be set to verbose = 1 or verbose = 2.\n",
    "\n",
    "Setting model.fit(verbose = 1) will\n",
    "\n",
    "output a progress bar in the terminal as the model trains.\n",
    "output the loss metric on the training set as the model trains.\n",
    "output the loss on the training and validation sets after each epoch.\n",
    "With model.fit(verbose = 2), Keras will only output the loss on the training set and validation set after each epoch.\n",
    "Model History Object\n",
    "When calling model.fit() or model.fit_generator(), Keras outputs a history object that contains the training and validation loss for each epoch. Here is an example of how you can use the history object to visualize the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0070 - val_loss: 0.0209\n",
      "Epoch 2/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0062 - val_loss: 0.0183\n",
      "Epoch 3/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0055 - val_loss: 0.0207\n",
      "Epoch 4/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0050 - val_loss: 0.0208\n",
      "Epoch 5/5\n",
      "19286/19286 [==============================] - 44s - loss: 0.0044 - val_loss: 0.0190\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOedcWvx/4zpOAJVFZOsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49fc41ecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_object = model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOedcWvx/4zpOAJVFZOsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48c1dbbeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators\n",
    "Here is an example of how you could use a generator to load data and preprocess it on the fly, in batch size portions to feed into your Behavioral Cloning model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "samples = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples[1:], test_size=0.2)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1608"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(samples[0])\n",
    "len(train_samples)\n",
    "len(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = './IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected lambda_input_20 to have 4 dimensions, but got array with shape (32, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-919cc29174b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m model.fit_generator(train_generator, \n\u001b[0;32m---> 19\u001b[0;31m                     samples_per_epoch=len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=3)\n\u001b[0m",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1551\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1552\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1308\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m   1031\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m   1032\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    110\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected lambda_input_20 to have 4 dimensions, but got array with shape (32, 1)"
     ]
    }
   ],
   "source": [
    "ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(Lambda(lambda x: (x/255.0)-0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(54,3,3,activation=\"relu\"))\n",
    "model.add(Convolution2D(54,3,3,activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(train_generator, \n",
    "                    samples_per_epoch=len(train_samples), validation_data=validation_generator, \n",
    "                    nb_val_samples=len(validation_samples), nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generator at 0x7f9b25810518>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Video in Autonomous Mode\n",
    "Because your hardware setup might be different from a reviewer's hardware setup, driving behavior could be different on your machine than on the reviewer's. To help with reviewing your submission, we require that you submit a video recording of your vehicle driving autonomously around the track. The video should include at least one full lap around the track. Keep in mind the rubric specifications:\n",
    "\n",
    "\"No tire may leave the drivable portion of the track surface. The car may not pop up onto ledges or roll over any surfaces that would otherwise be considered unsafe (if humans were in the vehicle).\"\n",
    "\n",
    "In the GitHub repo, we have included a file called video.py, which can be used to create the video recording when in autonomous mode.\n",
    "\n",
    "The README file in the GitHub repo contains instructions about how to make the video recording. Here are the instructions as well:\n",
    "\n",
    "```python drive.py model.h5 run1```\n",
    "\n",
    "The fourth argument, run1, is the directory in which to save the images seen by the agent. If the directory already exists, it'll be overwritten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image file name is a timestamp of when the image was seen.. This information is used by video.py to create a chronological video of the agent driving.\n",
    "### Using video.py\n",
    "```python video.py run1```\n",
    "\n",
    "Creates a video based on images found in the run1 directory. The name of the video will be the name of the directory followed by '.mp4', so, in this case the video will be run1.mp4.\n",
    "\n",
    "Optionally, one can specify the FPS (frames per second) of the video:\n",
    "\n",
    "```python video.py run1 --fps 48```\n",
    "\n",
    "The video will run at 48 FPS. The default FPS is 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
